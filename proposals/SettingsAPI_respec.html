<!DOCTYPE html>
<html>
  <head>
    <title>Proposal: Media Capture and Streams Settings API v6</title>
    <meta http-equiv='Content-Type' content='text/html;charset=utf-8' />
    <script src='http://darobin.github.com/respec/builds/respec-w3c-common.js' class='remove'></script>
    <script class='remove'>
        var respecConfig = {
            // document info
            specStatus: "ED",
            shortName: "settingsv6",
            // publishDate:   "2009-08-06",
            // previousMaturity: "WD",
            // previousPublishDate:  "2009-03-15",
            // previousURI : "http://dev.w3.org/2009/dap/ReSpec.js/documentation.html",
            copyrightStart: "2012",
            edDraftURI: "http://dvcs.w3.org/hg/dap/raw-file/tip/media-stream-capture/proposals/SettingsAPI_proposal_v6.html",
            // lcEnd:  "2010-08-06",

            // editors
            editors: [
                {
                    name: "Travis Leithead", company: "Microsoft", companyURL: "http://www.microsoft.com/"
                }
            ],
            prevED: "http://dvcs.w3.org/hg/dap/raw-file/79d50d0d9582/media-stream-capture/proposals/SettingsAPI_proposal_v6.html",

            // WG
            wg: ["Device APIs Working Group", "Web Real-Time Communications Working Group"],
            wgURI: ["http://www.w3.org/2009/dap/", "http://www.w3.org/2011/04/webrtc/"],
            wgPublicList: "public-media-capture",
            wgPatentURI: ["http://www.w3.org/2004/01/pp-impl/43696/status", "http://www.w3.org/2004/01/pp-impl/47318/status"],
            noIDLSorting: true,
            maxTocLevel: 3
        };
    </script>
  </head>
  <body>
    <section id='abstract'>
      This proposal describes additions and suggested changes to the 
        <a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html">Media Capture and Streams</a>
        specification in order to support the goal of device settings retrieval and modification. This proposal (v6) incorporates 
        feedback from the public-media-capture mailing list on the <a href="http://dvcs.w3.org/hg/dap/raw-file/999605452b3b/media-stream-capture/proposals/SettingsAPI_proposal_v5.html">Settings v5</a> proposal. The v5 proposal builds on four prior proposals with the same goal
        [<a href="http://dvcs.w3.org/hg/dap/raw-file/999605452b3b/media-stream-capture/proposals/SettingsAPI_proposal_v4.html">v4</a>]
        [<a href="http://lists.w3.org/Archives/Public/public-media-capture/2012Aug/0143.html">v3</a>]
        [<a href="http://lists.w3.org/Archives/Public/public-media-capture/2012Aug/0066.html">v2</a>]
        [<a href="http://lists.w3.org/Archives/Public/public-media-capture/2012Jul/0069.html">v1</a>].
    </section>

    <section>
        <h1>Evolution from V5</h1>
        <p>For those of you who have been following along, this section introduces you to some of the changes from the last version.</p>
        <p>For any of you just joining us, feel free to skip on down to the next section.</p>
        <p>As I was looking at source objects in V5, and starting to rationalize what properties of the source should go on the
            track, vs. on the source object, I got the notion that the source object really wasn't providing much value aside from 
            a logical separation for properties of the track vs. source. From our last telecon, it was apparent that most settings
            needed to be on the tracks as state-full information about the track. So, then what was left on the source?
        </p>
        <p>EKR's comments about wondering what happens when multiple apps (or tabs within a browser) go to access and manipulate
            a source also resonated with me. He proposed that this either be not allowed (exclusive locks on devices by apps), or 
            that this be better defined somehow.</p>
        <p>In thinking about this and wanting to have a better answer than the exclusive lock route, it occurred to me that when choosing 
            to grant a second app access to the same device, we might offer more than one choice. One choice that we've assumed so far, 
            is to share one device among two apps with either app having the ability to modify the devices' settings. Another option
            that I explore in this proposal is the concept of granting a read-only version of the device. There may be a primary owner
            in another app, or simply in another track instance that can change the settings, and the other track(s) can see and observe
            the changes, but cannot apply any changes of their own.
        </p>
        <p>In also thinking about allowing media other than strictly cameras and microphones with getUserMedia, such as a video from the
            user's hard drive, or an audio file, or even just a static image, it was apparent that sometimes the source for a track might
            be read-only anyway--you wouldn't be allowed to adjust the meta-data of a video streaming from the user's hard drive anyway.
        </p>
        <p>So the "read-only" media source concept was born.</p>
        <p>The set of source objects was now starting to grow. I could foresee it being difficult to rationalize/manage these objects, their
            purpose and/or properties into the future, and I as thought about all of these points together, it became clear that having 
            an explicit object defined for various source devices/things was unnecessary overhead and complication.
        </p>
        <p>As such, the source objects that came into existence in the v4 proposal as track sub-types, and were changed in v5 to be objects
            tied to tracks, are now gone. Instead, track sources have been simplified into a single string identifier on a track, which allows 
            the app to understand how access to various things about a track behave given a certain type of source (or no source).
        </p>
        <p>In order to clarify the track's behavior under various source types, I also had to get crisp about the things called "settings" 
            and the things called "constraints" and how they all work together. I think this proposal gets it right, and provides the right
            APIs for applications to manipulate what they want to in an easy to rationalize manner.
        </p>
        <p>And rather unfortunately (due to the name of the proposal), I've removed all notion of the term "settings" from this proposal. 
            The things previously called settings were a combination of constraints and capabilities, and now I've just formalized on the
            latter and given up on the former. It works--especially with long-lasting constraints and introspection of them.
        </p>
    </section>

    <section>
        <h1>Definitions</h1>
        <p>This proposal establishes the following definitions that I hope are used consistently throughout. (If not please let me know...)</p>
        <dl>
            <dt><dfn>Application</dfn></dt>
            <dd>The code that uses the APIs and interface defined in this specification. On the web, the application is authored in JavaScript and 
                tied to a particular domain, and typically runs inside of a single tab in browsers that offer tabbed browsing. In a browser it is 
                possible to be running multiple applications at one time in different domains/tabs. It is also possible that another application 
                outside of the browser and one inside of the browser may want to share media resources.
            </dd>
            <dt><dfn title="source">Source</dfn></dt>
            <dd>Sources are the "thing" providing the source of a media stream track. The source is the broadcaster of the media itself. A source
                can be a physical webcam, microphone, local video or audio file from the user's hard drive, network resource, or static image.
                <p>Individual sources have five basic <dfn title="mode">modes</dfn> that are not directly exposed to an application via any 
                    API defined in this spec. The modes are described in this spec for clarification purposes only:</p>
                <table class="simple">
                    <thead>
                        <tr><th>Source's Mode</th><th>Details</th></tr>
                    </thead>
                    <tbody>
                        <tr><td>unknown-authorization</td><td>The source hasn't yet been authorized for use by the 
                            application. (Authorization occurs via the getUserMedia API.) All sources start out in this mode at the start of the
                            application (though trusted hardware or software environments MAY automatically pre-authorize certain sources when 
                            their use is requested via getUserMedia). Camera or microphone sources that are visible to the user agent can make 
                            their existence known to the application in this mode. Other sources like files on the local file system do not.</td></tr>
                        <tr><td>armed</td><td>the source has been granted use by the application and is on/ready, but not actively broadcasting 
                            any media. This can be the case if a camera source has been authorized, but there are no sinks connected to this 
                            source (so no reason to be emitting media yet). Implementations of this specification are advised to include some 
                            indicator that a device is armed in their UI so that users are aware that an application may start the source at any 
                            time. A conservative user agent would enable some form of UI to show the source as "on" in this mode.</td></tr>
                        <tr><td>streaming</td><td>The source has been granted use by the application and is actively streaming media. User agents 
                            should provide an indicator to the user that the source is on and streaming in this mode.</td></tr>
                        <tr><td>not-authorized</td><td>This source has been forbidden/rejected by the user.</td></tr>
                        <tr><td>off</td><td>The source has been turned off, but is still detectable (its existence can still be confirmed) by the 
                            application.</td></tr>
                    </tbody>
                </table>
                <p>In addition to these modes, a source can be removed (physically in the case camera/microphone sources, or deleted in the case
                    of a file from the local file system), in which case it is no longer detectable by the application.</p>
                <p>The user MUST remain in control of the source at all times and can cause any state-machine mode transition.</p>
                <p>Some sources have an identifier which MUST be unique to the application (un-guessable by another application) and persistent between
                    application sessions (e.g., the identifier for a given source device/application must stay the same, but not be guessable by another
                    application). Sources that must have an identifier are camera and microphone sources; local file sources are not required to have 
                    an identifier. Source identifiers let the application save, identify the availability of, and directly request specific sources.
                </p>
                <p>Other than the identifier, other bits of source identify are <strong>never</strong> directly available to the application until the 
                    user agent connects a source to a track. Once a source has been "released" to the application (either via a permissions UI, pre-configured allow-list, or 
                    some other release mechanism) the application will be able discover additional source-specific capabilities.
                </p> 
                <p>Sources have <a>capabilities</a> and <a>state</a>. The capabilities and state are "owned" by the source and are common to any [multiple] tracks 
                    that happen to be using the same source (e.g., if two different tracks objects bound to the same source ask for the same capability 
                    or state information, they will get back the same answer).
                </p>
                <p>Sources <strong>do not</strong> have constraints--tracks have constraints. When a source is connected to a track, it must conform 
                    to the constraints present on that track (or set of tracks).
                </p>
                <p>Sources will be released (un-attached) from a track when the track is ended for any reason.</p>
                <p>On the track object, sources are represented by a <code><a>sourceType</a></code> attribute. The behavior of APIs associated with the 
                    source's capabilities and state change depending on the source type.
                </p>
            </dd>
            <dt><dfn title="state">State</dfn></dt>
            <dt>Source State</dt>
            <dd>State refers to the immediate, current value of the source's [optionally constrained] capabilities. State is always read-only.
                <p>A source's state can change dynamically over time due to environmental conditions, sink configurations, or constraint changes. A source's 
                    state must always conform to the current set of mandatory constraints that [each of] the tracks it is bound to have defined, and 
                    should do its best to conform to the set of optional constraints specified.
                </p>
                <p>A source's state is directly exposed to audio and video track objects through individual read-only attributes. These attributes share
                    the same name as their corresponding <a>capabilities</a> and <a>constraints</a>.
                </p>
                <p>Events are available that signal to the application that source state has changed.</p>
                <p>A conforming user-agent MUST support all the state names defined in this spec.</p>
            </dd>
            <dt><dfn title="capabilities">Capabilities</dfn></dt>
            <dd>
                Source capabilities are the intrinsic "features" of a source object. For each source state, there is a corresponding capability that describes
                whether it is supported by the source and if so, what the range of supported values are. Capability are expressed as either
                a series of states (for enumerated-type capabilities) or as a min/max range.
                <p>The values of the supported capabilities must be normalized to the ranges and enumerated types defined in this specification.</p>
                <p>Capabilities return the same underlying per-source capabilities, regardless of any user-supplied constraints 
                    present on the source (capabilities are independent of constraints).</p>
                <p>Source capabilities are effectively constant. Applications should be able to depend on a specific source having the same capabilities
                    for any session.
                </p>
            </dd>
            <dt><dfn title="constraints">Constraints</dfn></dt>
            <dd>
                Constraints are an optional feature for restricting the range of allowed variability on a source. Without provided constraints, implementations
                are free to select a source's state from the full range of its supported capabilities, and to adjust that state at any time for any reason.
                <p>Constraints may be optional or mandatory. Optional constraints are represented by an ordered list, mandatory constraints are an unordered
                    set. The order of the optional constraints is from most important (at the head of the list) to least important (at the tail of the list).
                </p>
                <p>Constraints are stored on the track object, not the source. Each track can be optionally initialized with constraints, or constraints can
                    be added afterward through the constraint APIs defined in this spec.
                </p>
                <p>Applying track level constraints to a source is conditional based on the type of source. For example, read-only sources
                    will ignore any specified constraints on the track.
                </p>
                <p>It is possible for two tracks that share a unique source to apply contradictory constraints. Under such contradictions, the implementation 
                    may be forced to transition to the source to the "armed" state until the conflict is resolved.
                </p>
                <p>Events are available that allow the application to know when constraints cannot be met by the user agent. These typically occur when
                    the application applies constraints beyond the capability of a source, contradictory constraints, or in some cases when a source 
                    cannot sustain itself in over-constrained scenarios (overheating, etc.). 
                </p>
                <p>Constraints that are intended for video sources will be ignored by audio sources and vice-versa. Similarly, constraints that are not
                    recognized will be preserved in the constraint structure, but ignored by the application. This will allow future constraints to be
                    defined in a backward compatible manner.
                </p>
                <p>A correspondingly-named constraint exists for each corresponding source state name and capability name.</p>
                <p>In general, user agents will have more flexibility to optimize the media streaming experience the fewer constraints are applied.</p>
            </dd>
        </dl>
    </section>

    <section>
        <h1>Tracks</h1>

        <p>With <a href="http://lists.w3.org/Archives/Public/public-media-capture/2012Dec/0027.html">proposed changes</a> to 
            <code>getUserMedia</code> to support a synchronous API, this proposal enables developer code to 
            directly create [derived] <code>MediaStreamTrack</code>s and initialize them with [optional] constraints. It also 
            adds the concept of the <code>"new"</code> readyState for tracks, a state which signifies that the track 
            is not connected to a source [yet].
        </p>

        <p>Below is the track hierarchy: new video and audio media streams are defined to inherit from <code>MediaStreamTrack</code>. The factoring into
            derived track types allows for <a>state</a> to be conveniently split onto the objects for which they make sense.
        </p>
        
        <ul>
            <li>MediaStreamTrack
                <ul>
                    <li>VideoStreamTrack</li>
                    <li>AudioStreamTrack</li>
                </ul>
            </li>
        </ul>

        <section>
            <h2>Generic Tracks</h2>

            <p>This section describes the <dfn>MediaStreamTrack</dfn> interface (currently in the Media Capture and Streams document), but makes targeted changes in order 
                to add the <code>"new"</code> state and associated event handler (<code>onstarted</code>). The definition is otherwise identical to the current definition except that the defined 
                constants are replaced by strings (using an enumerated type).
            </p>

            <section>
                <h3><code>MediaStreamTrack</code> interface</h3>
                <dl class="idl" title="interface MediaStreamTrack : EventTarget">
                    <dt>attribute DOMString id</dt>
                    <dd>Provides a mechanism for developers to assign and read-back the identify this track and to reference it using <code>MediaStream</code>'s 
                        <code>getTrackById</code>. (This is a preliminary definition, but is expected in the latest editor's draft soon.)
                    </dd>
                    <dt>readonly attribute DOMString kind</dt>
                    <dd>See <a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html#widl-MediaStreamTrack-kind">kind</a> definition in the current editor's draft.
                        <p class="issue"><strong>Issue: </strong> Is this attribute really necessary anymore? Perhaps we should drop it since application code will directly
                            create tracks from derived constructors: VideoStreamTrack and AudioStreamTrack?
                        </p>
                    </dd>
                    <dt>readonly attribute DOMString label</dt>
                    <dd>See <a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html#widl-MediaStreamTrack-label">label</a> definition in the current editor's draft.</dd>
                    <dt>attribute boolean enabled</dt>
                    <dd>See <a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html#widl-MediaStreamTrack-enabled">enabled</a> definition in the current editor's draft.</dd>
                    <dt>readonly attribute TrackReadyStateEnum readyState</dt>
                    <dd>The track's current state. Tracks start off in the <code>"new"</code> state after being instantiated.
                        <p>State transitions are as follows:</p>
                        <ul>
                            <li><strong>new -> live</strong> The user has approved access to this track and the attached <a>source</a> is in the "streaming" <a>mode</a>.</li>
                            <li><strong>new -> ended</strong> The user rejected this track (did not approve its use). No <a>source</a> is attached in this state.</li>
                            <li><strong>live -> muted</strong> The <a>source</a> transitioned from the "streaming" to the "armed" <a>mode</a>. This could be a result of applying mandatory 
                                constraints to a track that cannot be satisfied by the track's <a>source</a>.</li>
                            <li><strong>live -> ended</strong> The track has ended (for various reasons, including invoking the <code>stop()</code> API). No source object is attached.</li>
                            <li><strong>muted -> live</strong> The <a>source</a> transitioned from the "armed" to the "streaming" <a>mode</a>.</li>
                            <li><strong>muted -> ended</strong> The <a>source</a> was stopped while in the "armed" <a>mode</a>.</li>
                        </ul> 
                    </dd>
                    <dt>attribute EventHandler onstarted</dt>
                    <dd>Event handler for the <code>"started"</code> event. The <code>"started"</code> event is fired when this track transitions
                        from the <code>"new"</code> <code>readyState</code> to any other state. This event fires before any other corresponding events like <code>"ended"</code>
                        or <code>"statechanged"</code>.
                        <p class="issue"><strong>Recommendation: </strong> We should add a convenience API to <code>MediaStream</code> for being notified of various track changes 
                            like this one. The event would contain a reference to the track, as well as the name of the event that happened. Such a convenience API would 
                            fire last in the sequence of such events.
                        </p>
                    </dd>
                    <dt>attribute EventHandler onmute</dt>
                    <dd>See <a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html#widl-MediaStreamTrack-onmute">onmute</a> definition in the current editor's draft.
                    </dd>
                    <dt>attribute EventHandler onunmute</dt>
                    <dd>See <a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html#widl-MediaStreamTrack-onunmute">onunmute</a> definition in the current editor's draft.
                    </dd>
                    <dt>attribute EventHandler onended</dt>
                    <dd>See <a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html#widl-MediaStreamTrack-onended">onended</a> definition in the current editor's draft.
                    </dd>
                </dl>
            </section>

            <p>To support the above readyState changes, the following enumeration is defined:</p>

            <section>
                <h3>TrackReadyStateEnum enumeration</h3>
                <dl class="idl" title="enum TrackReadyStateEnum">
                    <dt>new</dt>
                    <dd>The track type is new and has not been initialized (connected to a source of any kind). This state implies that 
                        the track's label will be the empty string.</dd>
                    <dt>live</dt>
                    <dd>See the definition of the <a href="">LIVE</a> constant in the current editor's draft.</dd>
                    <dt>muted</dt>
                    <dd>See the definition of the <a href="">MUTED</a> constant in the current editor's draft. In addition, in this specification the <code>"muted"</code>
                        state can be entered when a track becomes over-constrained.
                    </dd>
                    <dt>ended</dt>
                    <dd>See the definition of the <a href="">ENDED</a> constant in the current editor's draft. In this specification, once a track enters this state
                        it never exits it.
                    </dd>
                </dl>
            </section>
        </section>

        <section>
            <h2>Track Sources</h2>

            <section>
                <h3>Track Source API Extensions to <a>MediaStreamTrack</a></h3>
                <dl class="idl" title="partial interface MediaStreamTrack">
                    <dt>readonly attribute SourceTypeEnum sourceType</dt>
                    <dd>Returns the type information associated with the currently attached source (if any).</dd>
                    <dt>readonly attribute DOMString sourceId</dt>
                    <dd>The application-unique identifier for this source. The same identifier MUST be valid between sessions of this application, but MUST also be different for other 
                        applications. Some sort of GUID is recommended for the identifier.</dd>
                    <dt>void stop()</dt>
                    <dd>Stops the source associated with this track (if any). If no source is attached (e.g., <a>sourceType</a> is "none"), then this call returns immediately (e.g., is a no-op).</dd>
                </dl>
            </section>

            <section>
                <h3>Track Source Types</h3>
                <p>The <dfn>sourceType</dfn> attribute may have the following states:</p>
                <dl class="idl" title="enum SourceTypeEnum">
                    <dt>none</dt>
                    <dd>This track has no source. This is the case when the track is in the <code>"new"</code> or <code>"ended"</code> <a>readyState</a>.</dd>
                    <dt>camera</dt>
                    <dd>A valid source type only for <a>VideoStreamTrack</a>s. The source is a local video-producing camera source (without special photo-mode support).</dd>
                    <dt>microphone</dt>
                    <dd>A valid source type only for <a>AudioStreamTrack</a>s. The source is a local audio-producing microphone source.</dd>
                    <dt>photo-camera</dt>
                    <dd>A valid source type only for <a>VideoStreamTrack</a>s. The source is a local video-producing camera source which supports high-resolution photo-mode and its related <a>state</a> attributes.</dd>
                    <dt>readonly</dt>
                    <dd>The track (audio or video) is backed by a read-only source such as a file, or the track source is a local microphone or camera, but is shared so that this track cannot modify any of the source's settings.</dd>
                    <dt>remote</dt>
                    <dd>The track is sourced by an <code>RTCPeerConnection</code>.</dd>
                </dl>
            </section>
        </section>

        <section>
            <h2>Video and Audio Tracks</h2>

            <p>The <a>MediaStreamTrack</a> object cannot be instantiated directly. To create an instance of a <a>MediaStreamTrack</a>, one of 
                its derived track types may be instantiated. These derived types are defined in this section.
            </p>

            <p>It's important to note that the camera's <q>green light</q> doesn't come on when a new track is created; nor does the user get 
                prompted to enable the camera/microphone. Those actions only happen after the developer has requested that a media stream containing 
                <code>"new"</code> tracks be bound to a source via <code>getUserMedia</code>. Until that point tracks are inert.
            </p>

            <section>
                <h3><code><dfn>VideoStreamTrack</dfn></code> interface</h3>

                <p>Video tracks may be instantiated with optional media track constraints. These constraints can be later modified on the track as
                    needed by the application, or created after-the-fact if the initial constraints are unknown to the application.
                </p>

                <p class="note"><strong>Example: </strong><a>VideoStreamTrack</a> objects are instantiated in JavaScript using the new operator: <br>
                    <tt><b>new</b> <code>VideoStreamTrack</code>();</tt><br>or<br>
                    <tt><b>new</b> <code>VideoStreamTrack</code>( { optional: [ { <code>sourceId</code>: "20983-20o198-109283-098-09812" }, { <code>width</code>: { min: 800, max: 1200 }}, { <code>height</code>: { min: 600 }}] });</tt>
                </p>

                <dl class="idl" title="[Constructor(optional MediaTrackConstraints videoConstraints)] interface VideoStreamTrack : MediaStreamTrack">
                    <dt>static sequence&lt;DOMString> getSourceIds()</dt>
                    <dd>Returns an array of application-unique source identifiers. This list will be populated only with local sources whose <a>sourceType</a> is <code>"camera"</code>, 
                        <code>"photo-camera"</code>, and if allowed by the user-agent, <code>"readonly"</code> variants of the former two types. The video source ids returned in the 
                        list constitute those sources that the user agent can identify at the time the API is called (the list can grow/shrink over time as sources may be added or 
                        removed). As a static method, <a>getSourceIds</a> can be queried without instantiating any <a>VideoStreamTrack</a> objects or without calling <code>getUserMedia</code>.
                        <p class="issue"><strong>Issue: </strong> This information deliberately adds to the fingerprinting surface of the UA. However, this information 
                            will not be identifiable outside the scope of this application. could also be obtained via other round-about techniques using <code>getUserMedia</code>. This editor deems it worthwhile directly providing
                            this data as it seems important for determining whether multiple devices of this type are available.
                        </p>
                    </dd>
                    <dt>void takePhoto()</dt>
                    <dd>If the <a>sourceType</a>'s value is anything other than <code>"photo-camera"</code>, this method returns immediately and does nothing.
                        If the <a>sourceType</a> is <code>"photo-camera"</code>, then this method temporarily (asynchronously) switches the source into "high 
                        resolution photo mode", applies the configured <a>photoWidth</a>, <a>photoHeight</a>, <a>exposureMode</a>, and <a>isoMode</a> <a>state</a>
                        to the stream, and records/encodes an image (using a user-agent determined format) into a <code>Blob</code> object. Finally, a task is
                        queued to fire a "photo" event with the resulting recorded/encoded data. In case of a failure for any reason, a "photoerror" event
                        is queued instead and no "photo" event is dispatched.
                        <p class="issue"><strong>Issue: </strong> We could consider providing a hint or setting for the desired photo format? There could be 
                            some alignment opportunity with the Recoding proposal...
                        </p>
                    </dd>
                    <dt>attribute EventHandler onphoto</dt>
                    <dd>Register/unregister for "photo" events. The handler should expect to get a BlobEvent object as its first
                        parameter.
                        <p class="note">The BlobEvent returns a photo (as a Blob) in a compressed format (for example: PNG/JPEG) rather than a 
                            raw ImageData object due to the expected large, uncompressed size of the resulting photos.</p>
                    </dd>
                    <dt>attribute EventHandler onphotoerror</dt>
                    <dd>In the event of an error taking the photo, a "photoerror" event will be dispatched instead of a "photo" event.
                        The "photoerror" is a simple event of type Event.
                    </dd>
                </dl>
            </section>

            <section>
                <h3>Photo-related Event Definitions</h3>

                <p><dfn>BlobEvent</dfn> interface</p>
                <dl class="idl" title="[Constructor(DOMString type, optional BlobEventInit blobInitDict)] interface BlobEvent : Event">
                    <dt>readonly attribute Blob data</dt>
                    <dd>Returns a Blob object whose type attribute indicates the encoding of the blob data. An implementation must
                        return a Blob in a format that is capable of being viewed in an HTML <code>&lt;img></code> tag.
                    </dd>
                </dl>
            
                <p>BlobEventInit dictionary</p>
                <dl class="idl" title="dictionary BlobEventInit : EventInit">
                    <dt>Blob data</dt>
                    <dd>A Blob object containing the data to deliver via this event.</dd>
                </dl>
            </section>
                    
            <section>
                <h3><code><dfn>AudioStreamTrack</dfn></code> interface</h3>
                
                <p class="note"><strong>Example: </strong><a>AudioStreamTrack</a> objects are instantiated in JavaScript using the new operator: <br>
                    <tt><b>new</b> <code>AudioStreamTrack</code>();</tt><br>or<br>
                    <tt><b>new</b> <code>AudioStreamTrack</code>( { optional: [ { <code>sourceId</code>: "64815-wi3c89-1839dk-x82-392aa" }, { <code>gain</code>: 0.5 }] });</tt>
                </p>

                <dl class="idl" title="[Constructor] interface AudioStreamTrack : MediaStreamTrack">
                    <dt>static sequence&lt;DOMString> getSourceIds()</dt>
                    <dd>See definition of <code>getSourceIds</code> on the <a>VideoStreamTrack</a> object. Note, that the list of source ids for <a>AudioStreamTrack</a> will be populated 
                        only with local sources whose <a>sourceType</a> is <code>"microphone"</code>, and if allowed by the user-agent, <code>"readonly"</code> microphone variants.
                    </dd>
                </dl>
            </section>
        </section>
    </section>
        
    <section>
        <h1>Source States</h1>

        <p>Source states (the current states of the source media flowing through a track) are observable by the attributes defined in this section. They are divided by 
            track type: video and audio.
        </p>

        <p>Note that the source states defined in this section do not include <a>sourceType</a> and <a>sourceId</a> merely because they were already defined earlier.
            These two attributes are also considered states, and have appropriate visibility as <a>capabilities</a> and <a>constraints</a>.
        </p>
      
        <section>
            <h2>Video Source State</h2>

            <p>This table summarizes the expected values of the video source state attributes for each of the <code><a>sourceType</a></code>s defined earlier:</p>

            <table class="simple">
                <thead>
                    <tr>
                        <th><code>sourceType</code></th>
                        <th>"none"</th>
                        <th>"camera"</th>
                        <th>"photo-camera"</th>
                        <th>"readonly"</th>
                        <th>"remote"</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>sourceType</code></td>
                        <td>current <a>SourceTypeEnum</a> value</td>
                        <td>current <a>SourceTypeEnum</a> value</td>
                        <td>current <a>SourceTypeEnum</a> value</td>
                        <td>current <a>SourceTypeEnum</a> value</td>
                        <td>current <a>SourceTypeEnum</a> value</td>
                    </tr>
                    <tr>
                        <td><code>sourceId</code></td>
                        <td>null</td>
                        <td>current <code>DOMString</code> value</td>
                        <td>current <code>DOMString</code> value</td>
                        <td>current <code>DOMString</code> value</td>
                        <td>null</td>
                    </tr>
                    <tr>
                        <td><code>width</code></td>
                        <td>null</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>current <code>unsigned long</code> value</td>
                    </tr>
                    <tr>
                        <td><code>height</code></td>
                        <td>null</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>current <code>unsigned long</code> value</td>
                    </tr>
                    <tr>
                        <td><code>frameRate</code></td>
                        <td>null</td>
                        <td>current <code>float</code> value</td>
                        <td>current <code>float</code> value</td>
                        <td>current <code>float</code> value</td>
                        <td>current <code>float</code> value</td>
                    </tr>
                    <tr>
                        <td><code>facingMode</code></td>
                        <td>null</td>
                        <td>current <a>VideoFacingModeEnum</a> value</td>
                        <td>current <a>VideoFacingModeEnum</a> value</td>
                        <td>current <a>VideoFacingModeEnum</a> value</td>
                        <td>null</td>
                    </tr>
                    <tr>
                        <td><code>zoom</code></td>
                        <td>null</td>
                        <td>current <code>float</code> value</td>
                        <td>current <code>float</code> value</td>
                        <td>current <code>float</code> value</td>
                        <td>null</td>
                    </tr>
                    <tr>
                        <td><code>focusMode</code></td>
                        <td>null</td>
                        <td>current <a>VideoFocusModeEnum</a> value</td>
                        <td>current <a>VideoFocusModeEnum</a> value</td>
                        <td>current <a>VideoFocusModeEnum</a> value</td>
                        <td>null</td>
                    </tr>
                    <tr>
                        <td><code>fillLightMode</code></td>
                        <td>null</td>
                        <td>current <a>VideoFillLightModeEnum</a> value</td>
                        <td>current <a>VideoFillLightModeEnum</a> value</td>
                        <td>current <a>VideoFillLightModeEnum</a> value</td>
                        <td>null</td>
                    </tr>
                    <tr>
                        <td><code>whiteBalanceMode</code></td>
                        <td>null</td>
                        <td>current <a>VideoWhiteBalanceModeEnum</a> value</td>
                        <td>current <a>VideoWhiteBalanceModeEnum</a> value</td>
                        <td>current <a>VideoWhiteBalanceModeEnum</a> value</td>
                        <td>null</td>
                    </tr>
                    <tr>
                        <td><code>brightness</code></td>
                        <td>null</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>null</td>
                    </tr>
                    <tr>
                        <td><code>contrast</code></td>
                        <td>null</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>null</td>
                    </tr>
                    <tr>
                        <td><code>saturation</code></td>
                        <td>null</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>null</td>
                    </tr>
                    <tr>
                        <td><code>sharpness</code></td>
                        <td>null</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>null</td>
                    </tr>
                    <tr>
                        <td><code>photoWidth</code></td>
                        <td>null</td>
                        <td>null</td>
                        <td>configured <code>unsigned long</code> value</td>
                        <td>configured <code>unsigned long</code> value (if readonly <a>source</a> is a photo-camera), <code>null</code> otherwise.</td>
                        <td>null</td>
                    </tr>
                    <tr>
                        <td><code>photoHeight</code></td>
                        <td>null</td>
                        <td>null</td>
                        <td>configured <code>unsigned long</code> value</td>
                        <td>configured <code>unsigned long</code> value (if readonly <a>source</a> is a photo-camera), <code>null</code> otherwise.</td>
                        <td>null</td>
                    </tr>
                    <tr>
                        <td><code>exposureMode</code></td>
                        <td>null</td>
                        <td>null</td>
                        <td>configured <a>PhotoExposureModeEnum</a> value</td>
                        <td>configured <a>PhotoExposureModeEnum</a> value (if readonly <a>source</a> is a photo-camera), <code>null</code> otherwise.</td>
                        <td>null</td>
                    </tr>
                    <tr>
                        <td><code>isoMode</code></td>
                        <td>null</td>
                        <td>null</td>
                        <td>configured <a>PhotoISOModeEnum</a> value</td>
                        <td>configured <a>PhotoISOModeEnum</a> value (if readonly <a>source</a> is a photo-camera), <code>null</code> otherwise.</td>
                        <td>null</td>
                    </tr>
                </tbody>
            </table>

            <section>
                <h3>Source State API Extensions to VideoStreamTrack</h3>
                <dl class="idl" title="partial interface VideoStreamTrack">
                    <dt>readonly attribute unsigned long? width</dt>
                    <dd>The width (in pixels) of the source of the video flowing through the track.</dd>
                    <dt>readonly attribute unsigned long? height</dt>
                    <dd>The height (in pixels) of the source of the video flowing through the track.</dd>
                    <dt>readonly attribute float? frameRate</dt>
                    <dd>The current frames per second rate of video provided by this source.
                        <p>If the <a>sourceType</a> is a <code>"camera"</code> or <code>"photo-camera"</code>, or a <code>"readonly"</code> variant of those, 
                            and the source does not provide a frameRate (or the frameRate cannot be determined from the source stream), then this attribute 
                            MUST be the user agent's vsync display rate.
                        </p>
                    </dd>
                    <dt>readonly attribute VideoFacingModeEnum? facingMode</dt>
                    <dd>From the user's perspective, this attribute describes whether this camera is pointed toward the 
                        user ("user") or away from the user ("environment").
                    </dd>
                    <dt>readonly attribute float? zoom</dt>
                    <dd>The current zoom scale value in use by the camera.
                        <p>If the <a>sourceType</a> is a <code>"camera"</code> or <code>"photo-camera"</code>, or a <code>"readonly"</code> variant of those, 
                            and the source does not support changing the zoom factor, then this attribute MUST always return the value <code>1.0</code>.
                        </p>
                    </dd>
                    <dt>readonly attribute VideoFocusModeEnum? focusMode</dt>
                    <dd>The source's current focusMode state.</dd>
                    <dt>readonly attribute VideoFillLightModeEnum? fillLightMode</dt>
                    <dd>The source's current fill light/flash mode.</dd>
                    <dt>readonly attribute VideoWhiteBalanceModeEnum? whiteBalanceMode</dt>
                    <dd>The source's current white balance mode.</dd>
                    <dt>readonly attribute unsigned long? brightness</dt>
                    <dd>The source's current brightness level. The values of this settings MUST range from 0 to 100.
                        <p>If the <a>sourceType</a> is a <code>"camera"</code> or <code>"photo-camera"</code>, or a <code>"readonly"</code> variant of those, 
                            and the source does not provide brightness level information, then this attribute MUST always return the value <code>50</code>.
                        </p>
                    </dd>
                    <dt>readonly attribute unsigned long? contrast</dt>
                    <dd>The source's current contrast level. The values of this settings MUST range from 0 to 100.
                        <p>If the <a>sourceType</a> is a <code>"camera"</code> or <code>"photo-camera"</code>, or a <code>"readonly"</code> variant of those, 
                            and the source does not provide contrast level information, then this attribute MUST always return the value <code>50</code>.
                        </p>
                    </dd>
                    <dt>readonly attribute unsigned long? saturation</dt>
                    <dd>The source's current saturation level. The values of this settings MUST range from 0 to 100. 
                        <p>If the <a>sourceType</a> is a <code>"camera"</code> or <code>"photo-camera"</code>, or a <code>"readonly"</code> variant of those, 
                            and the source does not provide saturation level information, then this attribute MUST always return the value <code>50</code>.
                        </p>
                    </dd>
                    <dt>readonly attribute unsigned long? sharpness</dt>
                    <dd>The source's current sharpness level. The values of this settings MUST range from 0 to 100. 
                        <p>If the <a>sourceType</a> is a <code>"camera"</code> or <code>"photo-camera"</code>, or a <code>"readonly"</code> variant of those, 
                            and the source does not provide sharpness level information, then this attribute MUST always return the value <code>50</code>.
                        </p>
                    </dd>
                    <dt>readonly attribute unsigned long? photoWidth</dt>
                    <dd>The width (in pixels) of the configured <a>sourceType</a>'s <code>"photo-camera"</code> (or <code>"readonly"</code> variant) high-resolution sensor.</dd>
                    <dt>readonly attribute unsigned long? photoHeight</dt>
                    <dd>The height (in pixels) of the configured <a>sourceType</a>'s <code>"photo-camera"</code> (or <code>"readonly"</code> variant) high-resolution sensor.</dd>
                    <dt>readonly attribute PhotoExposureModeEnum? exposureMode</dt>
                    <dd>The current value of the <a>sourceType</a>'s <code>"photo-camera"</code> (or <code>"readonly"</code> variant) light meter.</dd>
                    <dt>readonly attribute PhotoISOModeEnum? isoMode</dt>
                    <dd>The <a>sourceType</a>'s <code>"photo-camera"</code> (or <code>"readonly"</code> variant) film-equivalent speed (ISO) setting.</dd>
                </dl>
            </section>

            <section>
                <h3>Video Source State Supporting Enumerations</h3>

                <p><dfn>VideoFacingModeEnum</dfn> enumeration</p>
                <dl class="idl" title="enum VideoFacingModeEnum">
                    <dt>notavailable</dt>
                    <dd>The relative directionality of the source cannot be determined by the user agent based on the hardware.</dd>
                    <dt>user</dt>
                    <dd>The source is facing toward the user (a self-view camera).</dd>
                    <dt>environment</dt>
                    <dd>The source is facing away from the user (viewing the environment).</dd>
                </dl>
            
                <p><dfn>VideoFocusModeEnum</dfn> enumeration</p>
                <dl class="idl" title="enum VideoFocusModeEnum">
                    <dt>notavailable</dt>
                    <dd>This source does not have an option to change focus modes.</dd>
                    <dt>auto</dt>
                    <dd>The source auto-focuses.</dd>
                    <dt>manual</dt>
                    <dd>The source must be manually focused.</dd>
                </dl>
            
                <p><dfn>VideoFillLightModeEnum</dfn> enumeration</p>
                <dl class="idl" title="enum VideoFillLightModeEnum">
                    <dt>notavailable</dt>
                    <dd>This source does not have an option to change fill light modes (e.g., the camera does not have a flash).</dd>
                    <dt>auto</dt>
                    <dd>The video device's fill light will be enabled when required (typically low light conditions). Otherwise it will be 
                        off. Note that <code>auto</code> does not guarantee that a flash will fire when <code>takePhoto</code> is called. 
                        Use <code>flash</code> to guarantee firing of the flash for the <code>takePhoto</code> API. <code>auto</code> is the initial value.
                    </dd>
                    <dt>off</dt>
                    <dd>The source's fill light and/or flash will not be used.</dd>
                    <dt>flash</dt>
                    <dd>If the track's <a>sourceType</a> is <code>"photo-camera"</code>, this value will always cause the flash to fire
                        for the <code>takePhoto</code> API. Otherwise, for other supporting <a>sourceType</a>s, this value is equivalent
                        to <code>auto</code>.
                    </dd>
                    <dt>on</dt>
                    <dd>The source's fill light will be turned on (and remain on) while the source is in either <code>"armed"</code> or <code>"streaming"</code> <a>mode</a>.
                    </dd>
                </dl>

                <p><dfn>VideoWhiteBalanceModeEnum</dfn> enumeration</p>
                <dl class="idl" title="enum VideoWhiteBalanceModeEnum">
                    <dt>notavailable</dt><dd>The white-balance information is not available from this source.</dd>
                    <dt>auto</dt><dd>The white-balance is configured to automatically adjust.</dd>
                    <dt>incandescent</dt><dd>Adjust the white-balance between 2500 and 3500 Kelvin</dd>
                    <dt>cool-fluorescent</dt><dd>Adjust the white-balance between 4000 and 5000 Kelvin</dd>
                    <dt>warm-fluorescent</dt><dd>Adjust the white-balance between 5000 and 6000 Kelvin</dd>
                    <dt>daylight</dt><dd>Adjust the white-balance between 5000 and 6500 Kelvin</dd>
                    <dt>cloudy</dt><dd>Adjust the white-balance between 6500 and 8000 Kelvin</dd>
                    <dt>twilight</dt><dd>Adjust the white-balance between 8000 and 9000 Kelvin</dd>
                    <dt>shade</dt><dd>Adjust the white-balance between 9000 and 10,000 Kelvin</dd>
                </dl>

                <p><dfn>PhotoExposureModeEnum</dfn> enumeration</p>
                <dl class="idl" title="enum PhotoExposureModeEnum">
                    <dt>notavailable</dt><dd>The exposure mode is not known or not available on this source.</dd>
                    <dt>auto</dt><dd>The exposure mode is automatically configured/adjusted at the source's discretion.</dd>
                    <dt>frame-average</dt><dd>The light sensor should average of light information from entire scene.</dd>
                    <dt>center-weighted</dt><dd>The light sensor should bias sensitivity concentrated toward center of viewfinder.</dd>
                    <dt>spot-metering</dt><dd>The light sensor should only consider a centered spot area for exposure calculations.</dd>
                </dl>
            
                <p><dfn>PhotoISOModeEnum</dfn> enumeration</p>
                <dl class="idl" title="enum PhotoISOModeEnum">
                    <dt>notavailable</dt><dd>The ISO value is not known or not available on this source.</dd>
                    <dt>auto</dt><dd>The ISO value is automatically selected/adjusted at the source's discretion.</dd>
                    <dt>100</dt><dd>An ASA rating of 100</dd>
                    <dt>200</dt><dd>An ASA rating of 200</dd>
                    <dt>400</dt><dd>An ASA rating of 400</dd>
                    <dt>800</dt><dd>An ASA rating of 800</dd>
                    <dt>1250</dt><dd>An ASA rating of 1250</dd>
                </dl>
            </section>
        </section>

        <section>
            <h2>Audio Source State</h2>

            <p>This table summarizes the expected values of the video source state attributes for each of the <code><a>sourceType</a></code>s defined earlier:</p>

            <table class="simple">
                <thead>
                    <tr>
                        <th><code>sourceType</code></th>
                        <th>"none"</th>
                        <th>"microphone"</th>
                        <th>"readonly"</th>
                        <th>"remote"</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>sourceType</code></td>
                        <td>current <a>SourceTypeEnum</a> value</td>
                        <td>current <a>SourceTypeEnum</a> value</td>
                        <td>current <a>SourceTypeEnum</a> value</td>
                        <td>current <a>SourceTypeEnum</a> value</td>
                    </tr>
                    <tr>
                        <td><code>sourceId</code></td>
                        <td>null</td>
                        <td>current <code>DOMString</code> value</td>
                        <td>current <code>DOMString</code> value</td>
                        <td>null</td>
                    </tr>
                    <tr>
                        <td><code>volume</code></td>
                        <td>null</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>current <code>unsigned long</code> value</td>
                        <td>current <code>unsigned long</code> value</td>
                    </tr>
                    <tr>
                        <td><code>gain</code></td>
                        <td>null</td>
                        <td>current <code>float</code> value</td>
                        <td>current <code>float</code> value</td>
                        <td>null</td>
                    </tr>
                </tbody>
            </table>

            <section>
                <h3>Source State API Extensions to AudioStreamTrack</h3>
                <dl class="idl" title="partial interface AudioStreamTrack">
                    <dt>readonly attribute unsigned long? volume</dt>
                    <dd>The current audio track's volume (as a percentage). A volume of 0 is silence, while a volume of
                        100 is the maximum supported volume.
                    </dd>
                    <dt>readonly attribute float? gain</dt>
                    <dd>The sensitivity of the source. This value MUST be a positive floating-point number or zero. 
                        The gain value establishes the maximum threshold of the the microphone's sensitivity. When the gain is 0, 
                        the source is essentially off (it will not be able to pick-up any sound).
                        <p>If the <a>sourceType</a> is a <code>"microphone"</code> or a <code>"readonly"</code> microphone, 
                            and the source does not provide gain information, then this attribute MUST always return the value <code>1.0</code>.
                        </p>
                    </dd>
                </dl>
            </section>
        </section>

        <section>
            <h2>Tracking Source State Changes</h2>

            <p>As the source adjusts its state (for any reason), applications may observer the related state changes. The following 
                extensions to the MediaStreamTrack provide an alternative to polling the individual state attributes defined on the 
                video and audio track-types.
            </p>

            <section>
                <h3>Event Handlers and Object Definitions</h3>

                <p>The following event handler is added to the generic <a>MediaStreamTrack</a> interface.</p>

                <dl class="idl" title="partial interface MediaStreamTrack">
                    <dt>attribute EventHandler onstatechanged</dt>
                    <dd>Register/unregister for "statechanged" events. The handler should expect to get a <a>MediaStreamTrackStateEvent</a> object as its first
                        parameter. The event is fired asynchronously after the source changes its state.
                        <p>The user agent is encouraged to coalesce state changes into as few "statechanged" events as possible (when multiple state changes
                            occur within a reasonably short amount of time to each other).</p>
                        <p>The <code>"start"</code> event described earlier is a convenience event because a "statechanged" event will also
                            be fired when the <a>sourceType</a> changes from <code>"none"</code> to something else. The <code>"start"</code> event
                            MUST fire before the "statechanged" event fires.
                        </p>
                    </dd>
                </dl>

                <p>The following define the <dfn>MediaStreamTrackStateEvent</dfn> object and related initializer.</p>
                
                <dl class="idl" title="[Constructor(DOMString type, optional MediaStreamTrackStateEventInit eventInitDict)] interface MediaStreamTrackStateEvent : Event">
                    <dt>readonly attribute DOMString[] states</dt>
                    <dd>A list of state names that just changed values.</dd>
                </dl>
            
                <p>The initializer for the above-defined event type:</p>

                <dl class="idl" title="dictionary MediaStreamTrackStateEventInit : EventInit">
                    <dt>sequence&lt;DOMString> states</dt>
                    <dd>List of state names to populate into the MediaStreamTrackStateEvent object's states readonly attribute.</dd>
                </dl>
            </section>

        </section>

        <section>
            <h2>Out-of-scope State (Considered and Rejected from this Proposal)</h2>

            <p>The following settings have been proposed, but are not included in this version to keep the 
                initial set of settings scoped to those that:
            </p>
                
            <ol>
                <li>cannot be easily computed in post-processing</li>
                <li>are not redundant with other settings</li>
                <li>are settings found in nearly all devices (common)</li>
                <li>can be easily tested for conformance</li>
            </ol>

            <p>Each setting also includes a brief explanatory rationale for why it's not included:</p>

            <ol>
                <li><code>horizontalAspectRatio</code> - easily calculated based on width/height in the dimension values</li>
                <li><code>verticalAspectRatio</code> - see horizontalAspectRatio explanation</li>
                <li><code>orientation</code> - can be easily calculated based on the width/height values and the current rotation</li>
                <li><code>aperatureSize</code> - while more common on digital cameras, not particularly common on webcams (major use-case 
                    for this feature)</li>
                <li><code>shutterSpeed</code> - see aperatureSize explanation</li>
                <li><code>denoise</code> - may require specification of the algorithm processing or related image processing filter required
                    to implement.
                </li>
                <li><code>effects</code> - sounds like a v2 or independent feature (depending on the effect).</li>
                <li><code>faceDetection</code> - sounds like a v2 feature. Can also be done using post-processing techniques (though
                    perhaps not as fast...)
                </li>
                <li><code>antiShake</code>  - sounds like a v2 feature.</li>
                <li><code>geoTagging</code> - this can be independently associated with a recorded photo/video/audio clip using the 
                    Geolocation API. Automatically hooking up Geolocation to Media Capture sounds like an exercise for v2
                    given the possible complications.
                </li>
                <li><code>highDynamicRange</code> - not sure how this can be specified, or if this is just a v2 feature.</li>
                <li><code>skintoneEnhancement</code> - not a particularly common setting.</li>
                <li><code>shutterSound</code> - Can be accomplished by syncing custom audio playback via the <code>&lt;audio></code> tag if desired.
                    By default, there will be no sound issued.
                </li>
                <li><code>redEyeReduction</code> - photo-specific setting. (Could be considered if photo-specific settings
                    are introduced.)
                </li>
                <li><code>sceneMode</code> - while more common on digital cameras, not particularly common on webcams (major use-case 
                    for this feature)</li>
                <li><code>antiFlicker</code> - not a particularly common setting.</li>
                <li><code>zeroShutterLag</code> - this seems more like a <em>hope</em> than a setting. I'd rather just have implementations
                    make the shutter snap as quickly as possible after takePhoto, rather than requiring an opt-in/opt-out
                    for this setting.
                </li>
                <li><code>rotation</code> - rotation can be provided at the sink level if desired (CSS transforms on a video element).</li>
                <li><code>mirror</code> - mirroring can be provided at the sink level if desired (CSS transforms on a video element).</li>
                <li><code>bitRate</code> - this is more directly relevant to peer connection transport objects than track-level information.</li>
            </ol>
            
            <p>The following settings may be included by working group decision:</p>

            <ol>
                <li>exposureCompensation (is this the same as exposure?)</li>
                <li>evShift</li>
            </ol>
        </section>
    </section>

    <section>
        <h1>Source Capabilities</h1>

        <p>This section describes APIs for retrieving the capabilities of a given source. The return value of these APIs is contingent on
            the track's <a>sourceType</a> value as summarized in the table below.
        </p>

        <p>For each source <a>state</a> attribute defined (in the previous section), there is a corresponding capability associated with it.
            Capabilities are provided as either a min/max range, or a list of enumerated values but not both. Min/max capabilities are always provided
            for source <a>state</a> that are not enumerated types. Listed capabilities are always provided for source <a>state</a> corresponding
            to enumerated types.
        </p>
        
        <table class="simple">
            <thead>
                <tr>
                    <th><code>sourceType</code></th>
                    <th>"none"</th>
                    <th>"camera"/ "photo-camera"/ "microphone"</th>
                    <th>"readonly"</th>
                    <th>"remote"</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><code>capabilities()</code></td>
                    <td>null</td>
                    <td>(<a>AllVideoCapabilities</a> or <a>AllAudioCapabilities</a>)</td>
                    <td>(<a>AllVideoCapabilities</a> or <a>AllAudioCapabilities</a>)</td>
                    <td>null</td>
                </tr>
                <tr>
                    <td><code>getCapability()</code></td>
                    <td>null</td>
                    <td>(CapabilityRange or CapabilityList)</td>
                    <td>(CapabilityRange or CapabilityList)</td>
                    <td>null</td>
                </tr>
            </tbody>
        </table>

        <section>
            <h2>Source Capabilities API Extensions to MediaStreamTrack</h2>
            
            <dl class="idl" title="partial interface MediaStreamTrack">
                <dt>(CapabilityRange or CapabilityList) getCapability(DOMString stateName)</dt>
                <dd>
				    <dl class="parameters">
						<dt>DOMString stateName</dt><dd>The name of the source <a>state</a> for which the range of expected values should be returned.</dd>
					</dl>
                    
                    <p>If a capability is requested that does not have a corresponding <a>state</a> on the track-type, then a <code>null</code> value is returned (e.g., 
                        a <a>VideoStreamTrack</a> requests the <code>"gain"</code> capability. Since <code>"gain"</code> is not a state supported by video stream tracks, 
                        this API will return <code>null</code>).
                    </p>

                    <p>Given that implementations of various hardware may not exactly map to the same range, an implementation SHOULD make a reasonable attempt to 
                        translate and scale the hardware's setting onto the mapping provided by this specification. If this is not possible due to the user agent's
                        inability to retrieve a given capapbility from a source, then for <a>CapabilityRange</a>-typed capabilities, the <code>min</code> and <code>max</code>  
                        fields will not be present on the returned dictionary, and the <code>supported</code> field will be <code>false</code>. For <a>CapabilityList</a>-typed
                        capabilities, a suitable <code>"notavailable"</code> value will be the sole capability in the list.
                    </p>

                    <p class="note">An example of the user agent providing an alternative mapping: if a source supports a hypothetical fluxCapacitance state whose type
                        is a CapabilityRange, and the state is defined in this specification to be the range from -10 (min) to 10 (max), but the source's (hardware setting) 
                        for fluxCapacitance only supports values of "off" "medium" and "full", then the user agent should map the range value of -10 to "off", 10 should map 
                        to "full", and 0 should map to "medium". Constraints imposing a strict value of 3 will cause the user agent to attempt to set the value of "medium"
                        on the hardware, and return a fluxCapacitance <a>state</a> of 0, the closest supported setting. No error event is raised in this scenario.
                    </p>

                    <p>CapabilityList objects should order their enumerated values from minimum to maximum where it makes sense, or in 
                        the order defined by the enumerated type where applicable.
                    </p>

                    <p>See the <a>AllVideoCapabilities</a> and <a>AllAudioCapabilities</a> dictionary for details on the expected types for the various supported
                        state names.
                    </p>
                </dd>
                <dt>(AllVideoCapabilities or AllAudioCapabilities) capabilities()</dt>
                <dd>Returns a dictionary with all of the capabilities for the track type. If the track type is <a>VideoStreamTrack</a>, the 
                    <a>AllVideoCapabilities</a> dictionary is returned. If the track type is <a>AudioStreamTrack</a>, the 
                    <a>AllAudioCapabilities</a> dictionary is returned.
                    <p>The dictionaries are populated as if each <a>state</a> were requested individually using <code>getCapability()</code>,
                        and the results of that API are assigned as the value of each stateName in the dictionary. Notably, the returned values
                    </p>
                </dd>
            </dl>
        </section>

        <section>
            <h2>Source Capability Supporting Structures</h2>
            
            <p>CapabilityRange dictionary</p>
            <dl class="idl" title="dictionary CapabilityRange">
                <dt>any max</dt>
                <dd>The maximum value of this capability. 
                    <p>The type of this value is specific to the capability as noted in the table for <a>getCapability</a>.</p>
                    <p>If the related capability is not supported by the source, then this field will not be provided by the 
                        user agent (it will be <code>undefined</code>).
                    </p>
                </dd>
                <dt>any min</dt>
                <dd>The minimum value of this capability. 
                    <p>The type of this value is specific to the capability as noted in the table for <a>getCapability</a>.</p>
                    <p>If the related capability is not supported by the source, then this field will not be provided by the 
                        user agent (it will be <code>undefined</code>).
                    </p>
                </dd>
                <dt>boolean supported</dt>
                <dd>Returns the value <code>true</code> if the capability is supported, false otherwise.</dd>
            </dl>

            <p>CapabilityList array</p>

            <p>Capability Lists are just an array of supported <code>DOMString</code> values from the possible superset of 
                values described by each <a>state</a>'s enumerated type.</p>

            <dl class="idl" title="typedef sequence<DOMString> CapabilityList">
            </dl>
            
            <p>AllVideoCapabilities dictionary</p>

            <dl class="idl" title="dictionary AllVideoCapabilities">
                <dt>CapabilityList? sourceType</dt>
                <dd>The available sourceType options (<a>SourceTypeEnum</a>) on the current source.</dd>
                <dt>CapabilityList? sourceId</dt>
                <dd>The available source identifiers of the current source--this will always return a list with a single 
                    identifier (that of the current source). Note, to get a list of other available source identifiers,
                    use the static <a>getSourceIds</a> method.
                </dd>
                <dt>CapabilityRange? width</dt>
                <dd>The range should span the video source's pre-set width values with min being the smallest width, and max the 
                    largest width. The type of the min/max values are unsigned long.</dd>
                <dt>CapabilityRange? height</dt>
                <dd>
                    The range should span the video source's pre-set height values with min being the smallest width, and max the 
                    largest width. The type of the min/max values are unsigned long.
                </dd>
                <dt>CapabilityRange? frameRate</dt>
                <dd>The supported range of frame rates on the source. The type of the min/max values are float.</dd>
                <dt>CapabilityList? facingMode</dt>
                <dd>The available video facing options (<a>VideoFacingModeEnum</a>) on the source.</dd>
                <dt>CapabilityRange? zoom</dt>
                <dd>
                    The supported zoom range on the source. The type of the min/max/initial values are float. The initial value is 1. The float value is a scale
                    factor, for example 0.5 is zoomed out by double, while 2.0 is zoomed in by double. Requests should be rounded to the nearest supporting zoom 
                    factor by the implementation (when zoom is supported).
                </dd>
                <dt>CapabilityList? focusMode</dt>
                <dd>The available focus mode options (<a>VideoFocusModeEnum</a>) on the source.</dd>
                <dt>CapabilityList? fillLightMode</dt>
                <dd>The available fill light mode options (<a>VideoFillLightModeEnum</a>) on the source.</dd>
                <dt>CapabilityList? whiteBalanceMode</dt>
                <dd>The available white-balance mode options (<a>VideoWhiteBalanceModeEnum</a>) on the source.</dd>
                <dt>CapabilityRange? brightness</dt>
                <dd>The supported range of brightness on the source. The type of the min/max values are unsigned long.</dd>
                <dt>CapabilityRange? contrast</dt>
                <dd>The supported range of contrast on the source. The type of the min/max values are unsigned long.</dd>
                <dt>CapabilityRange? saturation</dt>
                <dd>The supported range of saturation on the source. The type of the min/max values are unsigned long.</dd>
                <dt>CapabilityRange? sharpness</dt>
                <dd>The supported range of sharpness on the source. The type of the min/max values are unsigned long.</dd>
                <dt>CapabilityRange? photoWidth</dt>
                <dd>
                    The range should span the video source's high-resolution photo-mode pre-set width values with min being the smallest width, and max the 
                    largest width. The type of the min/max/initial values are unsigned long.
                </dd>
                <dt>CapabilityRange? photoHeight</dt>
                <dd>
                    The range should span the video source's high-resolution photo-mode pre-set height values with min being the smallest width, and max the 
                    largest width. The type of the min/max/initial values are unsigned long.
                </dd>
                <dt>CapabilityList? exposureMode</dt>
                <dd>The available exposure mode options (<a>PhotoExposureModeEnum</a>) on the source.</dd>
                <dt>CapabilityList? isoMode</dt>
                <dd>The available ISO mode options (<a>PhotoISOModeEnum</a>) on the source.</dd>
            </dl>

            <p>AllAudioCapabilities dictionary</p>

            <dl class="idl" title="dictionary AllAudioCapabilities">
                <dt>CapabilityList? sourceType</dt>
                <dd>The available sourceType options (<a>SourceTypeEnum</a>) on the current source.</dd>
                <dt>CapabilityList? sourceId</dt>
                <dd>The available source identifiers of the current source--this will always return a list with a single 
                    identifier (that of the current source). Note, to get a list of other available source identifiers,
                    use the static <a>getSourceIds</a> method.
                </dd>
                <dt>CapabilityRange? volume</dt>
                <dd>
                    The supported range of output volume percentages on the source. The type of the min/max values are unsigned long.
                </dd>
                <dt>CapabilityRange? gain</dt>
                <dd>The supported gain range on the source. The type of the min/max values are float.</dd>
            </dl>
        </section>
    </section>

    <section>
        <h1>Track Constraints</h1>

        <p>This section contains an explanation of how constraint manipulation is expected to work with sources under various conditions. It also defines APIs 
            for working with the set of applied constraints on a track. Finally, it defines a set of constraint names matching the previously-defined 
            state attributes and capabilities.</p>

        <section>
            <h2>Constraints Manipulation Expectations</h2>

            <p>Browsers provide a media pipeline from sources to sinks.  In a browser, sinks are the &lt;img>, &lt;video> and &lt;audio> tags. Traditional sources 
				include camera, microphones, streamed content, files and web resources.  The media produced by these sources typically does not change over time - these sources can be 
				considered to be static.</p>
	
			<p>The sinks that display these sources to the user (the actual tags themselves) have a variety of controls for manipulating the source content.  For 
				example, an &lt;img> tag scales down a huge source image of 1600x1200 pixels to fit in a rectangle defined with <code>width="400"</code> and 
				<code>height="300"</code>.</p>

			<p>The getUserMedia API adds dynamic sources such as microphones and cameras - the characteristics of these sources can change in response to application 
				needs. These sources can be considered to be dynamic in nature. A &lt;video> element that displays media from a dynamic source can either perform 
				scaling or it can feed back information along the media pipeline and have the source produce content more suitable for display.</p>

			<p class="note"><strong>Note: </strong> This sort of feedback loop is obviously just enabling an "optimization", but it's a non-trivial gain. This 
				optimization can save battery, allow for less network congestion, etc...</p>

            <p>This proposal assumes that <code>MediaStream</code> sinks (such as <code>&lt;video></code>, <code>&lt;audio></code>, 
                and even <code>RTCPeerConnection</code>) will continue to have mechanisms to further transform the source stream beyond that
                which the <a>state</a>s, <a>capabilities</a>, and <a>constraints</a> described in this proposal offer. (The sink transformation options, including 
                those of <code>RTCPeerConnection</code> are outside the scope of this proposal.)</p>

            <p>The act of changing or applying a track constraint may affect the <a>state</a> of all tracks sharing that source and consequently all down-level sinks 
                that are using that source. Many sinks may be able to take these changes in stride, such as the <code>&lt;video></code> element or <code>RTCPeerConnection</code>. 
                Others like the Recorder API may fail as a result of a source state change.</p>

            <p>The <code>RTCPeerConnection</code> is an interesting object because it acts simultaneously as both a sink <strong>and</strong> a source for over-the-network
                streams. As a sink, it has source transformational capabilities (e.g., lowering bit-rates, scaling-up or down resolutions, adjusting frame-rates), and as a
                source it could have its own settings changed by a track source (though in this proposal <a>sourceType</a>s of type <code>"remote"</code> do not consider 
                the current constraints applied to a track).
            </p>

            <p>To illustrate how changes to a given source impact various sinks, consider the following example. This example only uses width and height, but the same
                principles apply to any of the <a>state</a>s exposed in this proposal. In the first figure a home client has obtained a video source
                from its local video camera. The source's width and height state are 800 pixels by 600 pixels, respectively. Three <code>MediaStream</code> objects on the 
                home client contain tracks that use this same <a>sourceId</a>. The three media streams are connected to three different sinks, a <code>&lt;video></code> element (A), 
                another <code>&lt;video></code> element (B), and a peer connection (C). The peer connection is streaming the source video to an away client. On the away client
                there are two media streams with tracks that use the peer connection as a source. These two media streams are connected to two <code>&lt;video></code> element
                sinks (Y and Z).
            </p>
            
            <img src="change_settings_before.png" title="Changing media stream source effects: before the requested change">

            <p>Note that at this moment, all of the sinks on the home client must apply a transformation to the original source's provided state dimensions. A is scaling the video up
                (resulting in loss of quality), B is scaling the video down, and C is also scaling the video up slightly for sending over the network. On the away client, sink 
                Y is scaling the video way down, while sink Z is not applying any scaling.
            </p>

            <p>Using the constraint APIs defined in the next section, the home client's video source is changed to a higher resolution (1920 by 1200 pixels).</p>

            <img src="change_settings_after.png" title="Changing media stream source effects: after the requested change">

            <p>Note that the source change immediately effects all of the sinks on home client, but does not impact any of the sinks (or sources) on the away client. With the 
                increase in the home client source video's dimensions, sink A no longer has to perform any scaling, while sink B must scale down even further than before.
                Sink C (the peer connection) must now scale down the video in order to keep the transmission constant to the away client.
            </p>

            <p>While not shown, an equally valid settings change request could be made of the away client video source (the peer connection on the away client's side).
                This would not only impact sink Y and Z in the same manner as before, but would also cause re-negotiation with the peer connection on the home 
                client in order to alter the transformation that it is applying to the home client's video source. Such a change <strong>would not</strong> change anything
                related to sink A or B or the home client's video source.
            </p>
			
			<p class="note"><strong>Note: </strong> This proposal does not define a mechanism by which a change to the away client's video source could
                automatically trigger a change to the home client's video source. Implementations may choose to make such source-to-sink optimizations as long as they only
				do so within the constraints established by the application, as the next example describes.
            </p>
			
			<p>It is fairly obvious that changes to a given source will impact sink consumers. However, in some situations changes to a given sink may also be cause for 
				implementations to adjust the characteristics of a source's stream. This is illustrated in the following figures. In the first figure below, the home 
				client's video source is sending a video stream sized at 1920 by 1200 pixels. The video source is also unconstrained, such that the exact source dimensions 
				are flexible as far as the application is concerned. Two <code>MediaStream</code> objects contain tracks with the same <a>sourceId</a>, and those 
				<code>MediaStream</code>s are connected to two different <code>&lt;video></code> element sinks A and B. Sink A has been sized to <code>width="1920"</code> and 
				<code>height="1200"</code> and is displaying the source's video content without any transformations. Sink B has been sized smaller and as a result, is scaling the 
				video down to fit its rectangle of 320 pixels across by 200 pixels down.
			</p>

			<img src="change_settings_before2.png" title="Changing media stream sinks may affect sources: before the requested change">
			
			<p>When the application changes sink A to a smaller dimension (from 1920 to 1024 pixels wide and from 1200 to 768 pixels tall), the browser's media pipeline may 
				recognize that none of its sinks require the higher source resolution, and needless work is being done both on the part of the source and on sink A. In 
				such a case and without any other constraints forcing the source to continue producing the higher resolution video, the media pipeline may change the source
				resolution:</p>
				
			<img src="change_settings_after2.png" title="Changing media stream sinks may affect sources: after the requested change">
            
			<p>In the above figure, the home client's video source resolution was changed to the max(sinkA, sinkB) in order to optimize playback. While not shown above, the
				same behavior could apply to peer connections and other sinks.</p>
        </section>

        <section>
            <h2>Constraint Manipulation API Extensions to MediaStreamTrack</h2>

            <p>Constraints are independent of sources. However, depending on the <a>sourceType</a> the track's constraints may or may not actually be considered by the user 
                agent. The following table summarizes the expectations around track constraints given a <a>sourceType</a>.
            </p>

            <table class="simple">
                <thead>
                    <tr>
                        <th><code>sourceType</code></th>
                        <th>"none"</th>
                        <th>"camera"/<br>"photo-camera"/<br>"microphone"</th>
                        <th>"readonly"</th>
                        <th>"remote"</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Constraints apply to <a>sourceType</a>?</td>
                        <td>No</td>
                        <td>Yes</td>
                        <td>No</td>
                        <td>No
                            <p class="issue"><strong>Issue: </strong>This may be too cut-and-dry. Maybe <em>some</em> of the constraints should apply?</p>
                        </td>
                    </tr>
                </tbody>
            </table>

            <p>Whether <code>MediaTrackConstraints</code> were provided at track initialization time or need to be established later at runtime, the APIs defined below allow 
                the retrieval and manipulation of the constraints currently established on a track.
            </p>

            <p>Each track maintains an internal version of the <code>MediaTrackConstraints</code> structure, namely a mandatory set of constraints (no duplicates),
                and an optional ordered list of individual constraint objects (may contain duplicates). The internal stored constraint structure is only exposed 
                to the application using the existing <code>MediaTrackConstraints</code>, <code>MediaTrackConstraintSet</code>, <code>MediaTrackConstraint</code>, 
                and similarly-derived-type dictionary objects.
            </p>

            <p>When track constraints change, a user agent MUST queue a task to evaluate those changes when the task queue is next serviced. Similarly, if the
                <a>sourceType</a> changes, then the user agent should perform the same actions to re-evaluate the constraints of each track affected by that source
                change.
            </p>

            <dl class="idl" title="partial interface MediaStreamTrack">
                <dt>any getConstraint(DOMString constraintName, optional boolean mandatory = false)</dt>
                <dd>
					<dl class="parameters">
						<dt>DOMString constraintName</dt><dd>The name of the setting for which the current value of that setting should be returned</dd>
                        <dt>optional boolean mandatory = false</dt><dd><code>true</code> to indicate that the constraint should be looked up in the mandatory set of constraints,
                            otherwise, the constraintName should be retrieved from the optional list of constraints.</dd>
					</dl>
                    <p>Retrieves a specific named constraint value from the track. The named constraints are the same names used for the <a>capabilities</a> API, and also
                        are the same names used for the source's <a>state</a> attributes.
                    </p>
                    Returns one of the following types:
                    <dl>
                        <dt><strong>null</strong></dt>
                        <dd>If no constraint matching the provided constraintName exists in the respective optional or mandatory set on this track.</dd>
                        <dt><strong>sequence&lt;MediaTrackConstraint></strong></dt>
                        <dd>If the mandatory flag is false and there is at least one optional matching constraint name defined on this track. 
                            <p>Each MediaTrackConstraint result in the list will contain a key which matches the requested <a>constraintName</a> parameter, 
                                and whose value will either be a primitive value, or a <a>MinMaxConstraint</a> object.
                            </p>
                            <p>The returned list will be ordered from most important-to-satisfy at index <code>0</code>, to the least-important-to-satisfy
                                optional constraint.</p>
                            <p class="note"><strong>Example: </strong>Given a track with an internal constraint structure:<tt style="white-space:pre">
{
  <code>mandatory</code>: {
    width: { min: 640 },
    height: { min: 480 }
  },
  <code>optional</code>: [
    { width: 650 },
    { width: { min: 650, max: 800 }},
    { frameRate: 60 },
    { fillLightMode: "off" },
    { facingMode: "user" }
  ]
}                                
</tt>
                            and a request for <code>getConstraint("width")</code>, the following list would be returned:<tt style="white-space:pre">
[
    { width: 650 },
    { width: { min: 650, max: 800 }}
]
</tt>
                            </p>
                        </dd>
                        <dt><strong>MinMaxConstraint</strong></dt>
                        <dd>If the mandatory flag is true, and the requested constraint is defined in the mandatory <code>MediaTrackConstraintSet</code> associated 
                            with this track, and the value of the constraint is a min/max range object.
                        </dd>
                        <dt><strong><em>primitive_value</em></strong></dt>
                        <dd>If the mandatory flag is true, and the requested constraint is defined in the mandatory <code>MediaTrackConstraintSet</code> associated 
                            with this track, and the value of the constraint is a primitive value (DOMString, unsigned long, float, etc.).
                        </dd>
                    </dl>
                </dd>
                <dt>void setConstraint(DOMString constraintName, any constraintValue, optional boolean mandatory = false)</dt>
                <dd>
					<dl class="parameters">
						<dt>DOMString constraintName</dt><dd>The name of the constraint to set.</dd>
						<dt>any constraintValue</dt><dd>Either a primitive value (float/DOMString/etc), or a <a>MinMaxConstraint</a> dictionary.</dd>
                        <dt>optional boolean mandatory = false</dt><dd>A flag indicating whether this constraint should be applied to the optional 
                            or mandatory constraints.</dd>
					</dl>
                    <p>This method updates the value of a same-named existing constraint (if found) in either the mandatory or optional list, and otherwise sets 
                        the new constraint.</p>
                    <p>This method searches the list of optional constraints from index <code>0</code> (highest priority) to the end of the list (lowest priority)
                        looking for matching constraints. Therefore, for multiple same-named optional constraints, this method will only update the
                        value of the highest-priority matching constraint.
                    </p>
                    <p>If the <code>mandatory</code> flag is <code>false</code> and the constraint is not found in the list of optional constraints, then
                        a new optional constraint is created and appended to the end of the list (thus having lowest priority).</p>
                    <p class="note"><strong>Note: </strong>This behavior allows applications to iteratively call <code>setConstraint</code> and have their 
                        constraints added in the order specified in the source.
                    </p>
                </dd>
                <dt>MediaTrackConstraints? constraints()</dt>
                <dd>Returns the complete constraints object associated with the track. If no mandatory constraints have been defined, the <code>mandatory</code>
                    field will not be present (it will be undefined). If no optional constraints have been defined, the <code>optional</code> field will not be
                    present (it will be undefined). If neither optional, nor mandatory constraints have been created, the value <code>null</code> is returned. 
                </dd>
                <dt>void applyConstraints(MediaTrackConstraints constraints)</dt>
                <dd>
                    <dl class="parameters">
                        <dt>MediaTrackConstraints constraints</dt><dd>A new constraint structure to apply to this track.</dd>
                    </dl>
                    <p>This API will replace all existing constraints with the provided constraints (if existing constraints exist).
                        Otherwise, it will apply the newly provided constraints to the track.
                    </p>
                </dd>
                <dt>void prependConstraint(DOMString constraintName, any constraintValue)</dt>
                <dd>
                    <dl class="parameters">
						<dt>DOMString constraintName</dt><dd>The name of the constraint to prepend to the list of optional constraints.</dd>
						<dt>any constraintValue</dt><dd>Either a primitive value (float/DOMString/etc), or a <a>MinMaxConstraint</a> dictionary.</dd>
					</dl>
                    <p>Prepends (inserts before the start of the list) the provided constraint name and value. This method does not consider whether
                        a same-named constraint already exists in the optional constraints list.
                    </p>
                    <p>This method applies exclusively to optional constraints; it does not modify mandatory constraints.</p>
                    <p>This method is a convenience API for programmatically building constraint structures.</p>
                </dd>
                <dt>void appendConstraint(DOMString constraintName, any constraintValue)</dt>
                <dd>
                    <dl class="parameters">
						<dt>DOMString constraintName</dt><dd>The name of the constraint to append to the list of optional constraints.</dd>
						<dt>any constraintValue</dt><dd>Either a primitive value (float/DOMString/etc), or a <a>MinMaxConstraint</a> dictionary.</dd>
					</dl>
                    <p>Appends (at the end of the list) the provided constraint name and value. This method does not consider whether
                        a same-named constraint already exists in the optional constraints list.</p>
                    <p>This method applies exclusively to optional constraints; it does not modify mandatory constraints.</p>
                    <p>This method is a convenience API for programmatically building constraint structures.</p>
                </dd>
                <dt>attribute EventHandler onoverconstrained</dt>
                <dd>Register an event handler for the "overconstrained" event. This event fires asynchronously for each affected track (when multiple
                    tracks share the same source) after the user agent has evaluated the current constraints against a given <a>sourceId</a> and is
                    not able to configure the source within the limitations established by the union of imposed constraints.
                    <p>This event may also fire when <a>takePhoto</a> is called and the source cannot record/encode an image due to over-constrained
                        or conflicting constraints of those uniquely related to <a>sourceType</a>s of type <code>"photo-camera"</code>.</p>
                    <p>Due to being over-constrained, the user agent MUST transition the source to the <code>"armed"</code> <a>mode</a>, which may
                        result in also dispatching one or more "muted" events to affected tracks.
                    </p>
                    <p>The affected track(s) will remain un-usable (in the <code>"muted"</code> <a>readyState</a>) until the application adjusts the 
                        constraints to accommodate the source's capabilities.</p>
                    <p>The "overconstrained" event is a simple event of type <code>Event</code>; it carries no information about which constraints 
                        caused the source to be over-constrained (the application has all the necessary APIs to figure it out).
                    </p>
                </dd>
            </dl>

            <section>
                <h3>Constraint Definitions and Related Structures</h3>
                
                <p>The following constraint names are defined to apply to both <a>VideoStreamTrack</a> and <a>AudioStreamTrack</a> objects:</p>

                <table class="simple">
                    <thead>
                        <tr>
                            <th>Constraint Name</th>
                            <th>Values</th>
                            <th>Notes</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr id="def-constraint-sourceType">
                            <td>sourceType</td>
                            <td><a>SourceTypeEnum</a></td>
                            <td>Constrain the video or audio source to an exact value from the set of enumerated-type values of the <a>SourceTypeEnum</a>.</td>
                        </tr>
                        <tr id="def-constraint-sourceId">
                            <td>sourceId</td>
                            <td>DOMString</td>
                            <td>Constrain the video or audio source to an exact source identifier value.</td>
                        </tr>
                    </tbody>
                </table>

                <p>The following constraint names are defined to apply only to <a>VideoStreamTrack</a> objects:</p>

                <table class="simple">
                    <thead>
                        <tr>
                            <th>Constraint Name</th>
                            <th>Values</th>
                            <th>Notes</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr id="def-constraint-width">
                            <td>width</td>
                            <td>unsigned long or <a>MinMaxConstraint</a></td>
                            <td>Constrain the video source to the exact desired width or width range.</td>
                        </tr>
                        <tr id="def-constraint-height">
                            <td>height</td>
                            <td>unsigned long or <a>MinMaxConstraint</a></td>
                            <td>Constrain the video source to the exact desired height or height range.</td>
                        </tr>
                        <tr id="def-constraint-frameRate">
                            <td>frameRate</td>
                            <td>float or <a>MinMaxConstraint</a></td>
                            <td>Constrain the video source to the exact desired frame rate (fps) or frameRate range.</td>
                        </tr>
                        <tr id="def-constraint-facingMode">
                            <td>facingMode</td>
                            <td><a>VideoFacingModeEnum</a></td>
                            <td>Constrain the video source to an exact value from the set of enumerated-type values of the <a>VideoFacingModeEnum</a>.</td>
                        </tr>
                        <tr id="def-constraint-zoom">
                            <td>zoom</td>
                            <td>float or <a>MinMaxConstraint</a></td>
                            <td>Constrain the video source to the exact desired zoom ratio or zoom ratio range.</td>
                        </tr>
                        <tr id="def-constraint-focusMode">
                            <td>focusMode</td>
                            <td><a>VideoFocusModeEnum</a></td>
                            <td>Constrain the video source to an exact value from the set of enumerated-type values of the <a>VideoFocusModeEnum</a>.</td>
                        </tr>
                        <tr id="def-constraint-fillLightMode">
                            <td>fillLightMode</td>
                            <td><a>VideoFillLightModeEnum</a></td>
                            <td>Constrain the video source to an exact value from the set of enumerated-type values of the <a>VideoFillLightModeEnum</a>.</td>
                        </tr>
                        <tr id="def-constraint-whiteBalanceMode">
                            <td>whiteBalanceMode</td>
                            <td><a>VideoWhiteBalanceModeEnum</a></td>
                            <td>Constrain the video source to an exact value from the set of enumerated-type values of the <a>VideoWhiteBalanceModeEnum</a>.</td>
                        </tr>
                        <tr id="def-constraint-brightness">
                            <td>brightness</td>
                            <td>unsigned long or <a>MinMaxConstraint</a></td>
                            <td>Constrain the video source to the exact desired brightness or brightness range.</td>
                        </tr>
                        <tr id="def-constraint-contrast">
                            <td>contrast</td>
                            <td>unsigned long or <a>MinMaxConstraint</a></td>
                            <td>Constrain the video source to the exact desired contrast or contrast range.</td>
                        </tr>
                        <tr id="def-constraint-saturation">
                            <td>saturation</td>
                            <td>unsigned long or <a>MinMaxConstraint</a></td>
                            <td>Constrain the video source to the exact desired saturation or saturation range.</td>
                        </tr>
                        <tr id="def-constraint-sharpness">
                            <td>sharpness</td>
                            <td>unsigned long or <a>MinMaxConstraint</a></td>
                            <td>Constrain the video source to the exact desired sharpness or sharpness range.</td>
                        </tr>
                        <tr id="def-constraint-photoWidth">
                            <td>photoWidth</td>
                            <td>unsigned long or <a>MinMaxConstraint</a></td>
                            <td>Constrain the width of the photo produced by the <a>takePhoto</a> method to the exact desired width or width range.</td>
                        </tr>
                        <tr id="def-constraint-photoHeight">
                            <td>photoHeight</td>
                            <td>unsigned long or <a>MinMaxConstraint</a></td>
                            <td>Constrain the height of the photo produced by the <a>takePhoto</a> method to the exact desired height or height range.</td>
                        </tr>
                        <tr id="def-constraint-exposureMode">
                            <td>exposureMode</td>
                            <td><a>PhotoExposureModeEnum</a></td>
                            <td>Constrain the exposure used for the photo produced by the <a>takePhoto</a> method to an exact value from the set of enumerated-type values of the <a>PhotoExposureModeEnum</a>.</td>
                        </tr>
                        <tr id="def-constraint-isoMode">
                            <td>CapabilityList? isoMode</td>
                            <td><a>PhotoISOModeEnum</a></td>
                            <td>Constrain the ISO mode used for the photo produced by the <a>takePhoto</a> method to an exact value from the set of enumerated-type values of the <a>PhotoISOModeEnum</a>.</td>
                        </tr>
                    </tbody>
                </table>

                <p>The following constraint names are defined to apply only to <a>AudioStreamTrack</a> objects:</p>
                
                <table class="simple">
                    <thead>
                        <tr>
                            <th>Constraint Name</th>
                            <th>Values</th>
                            <th>Notes</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr id="def-constraint-volume">
                            <td>volume</td>
                            <td>unsigned long or <a>MinMaxConstraint</a></td>
                            <td>Constrain the audio source to the exact desired volume or volume range.</td>
                        </tr>
                        <tr id="def-constraint-gain">
                            <td>gain</td>
                            <td>float or <a>MinMaxConstraint</a></td>
                            <td>Constrain the audio source to the exact desired gain or gain range.</td>
                        </tr>
                    </tbody>
                </table>

                <p>For constraints that accept ranges, the <a>MinMaxConstraint</a> dictionary is also defined. Note, that the type 
                    of the value associated with <code>min</code> and <code>max</code> must be the same for both. The specific 
                    types associated with <code>min</code> and <code>max</code> are defined differently for each constraint name.</p>

                <dl class="idl" title="dictionary MinMaxConstraint">
                    <dt>any max</dt><dd>The related constraint's maximum allowed value.</dd>
                    <dt>any min</dt><dd>The related constraint's minimum allowed value.</dd>
                </dl>
        
            </section>
        </section>
    </section>

    <section>
        <h1>Example usage scenarios</h1>

        <p>The following JavaScript examples demonstrate how the Settings APIs defined in this proposal could be used.</p>

        <section>
            <h2>Getting access to a video and audio device (if available)</h2>

            <pre>
var audioTrack = (AudioStreamTrack.getSourceIds().length > 0) ? new AudioStreamTrack() : null;
var videoTrack = (VideoStreamTrack.getSourceIds().length > 0) ? new VideoStreamTrack() : null;
if (audioTrack && videoTrack) {
   videoTrack.onstarted = mediaStarted;
   var MS = new MediaStream();
   MS.addTrack(audioTrack);
   MS.addTrack(videoTrack);
   navigator.getUserMedia(MS);
}

function mediaStarted() {
   // One of the video/audio devices started (assume both, but may not be strictly true if the user doesn't approve both tracks)
}
</pre>
        </section>

        <section>
            <h2>Getting access to a specific video source (if available)</h2>

            <pre>
var lastUsedSourceId = localStorage["last-source-id"];
var lastUsedSourceIdAvailable = false;
VideoStreamTrack.getSourceIds().forEach(function (sourceId) { if (sourceId == lastUsedSourceId) lastUsedSourceIdAvailable = true; });
if (lastUsedSourceIdAvailable) {
   // Request this specific source...
   var vidTrack = new VideoStreamTrack( { mandatory: { sourceId: lastUsedSourceId }});
   vidTrack.onoverconstrained = function() { alert("User, why didn't to give me access to the same source? I know you have it..."); }
   navigator.getUserMedia(new MediaStream([vidTrack]));
}
else
   alert("User could you plug back in that camera you were using on this page last time?");
</pre>
        </section>


        <section>
            <h2>Previewing the local video/audio in HTML5 video tag -- scenario is unchanged</h2>

            <pre>
function mediaStarted() {
   // objectURL technique
   document.querySelector("video").src = URL.createObjectURL(MS, { autoRevoke: true }); // autoRevoke is the default
   // direct-assign technique
   document.querySelector("video").srcObject = MS; // Proposed API at this time
}
</pre>
        </section>

        <section>
            <h2>Applying resolution constraints</h2>

            <pre>
function mediaStarted() {
   videoTrack;
   var maxWidth = videoTrack.getCapability("width").max;
   var maxHeight = videoTrack.getCapability("height").max;
   // Check for 1080p+ support
   if ((maxWidth >= 1920) && (maxHeight >= 1080)) {
      // See if I need to change the current settings...
      if ((videoTrack.width &lt; 1920) && (videoTrack.height &lt; 1080)) {
         videoTrack.setConstraint("width", maxWidth);
         videoTrack.setConstraint("height", maxHeight);
         videoTrack.onoverconstrained = failureToComply;
         videoTrack.onstatechanged = didItWork;
      }
   }
   else
      failureToComply();
}

function failureToComply(e) {
   if (e)
      console.error("Devices failed to change " + e.settings); // 'width' and/or 'height'
   else
      console.error("Device doesn't support at least 1080p");
}

function didItWork(e) {
   e.states.forEach( function (state) { if ((state == "width") || (state == "height")) alert("Resolution changed!"); });
}
</pre>
        </section>

        <section>
            <h2>Changing zoom in response to user input:</h2>

            <pre>
function mediaStarted() {
   setupRange( videoTrack );
}

function setupRange(videoTrack) {
   var zoomCaps = videoTrack.getCapability("zoom");
   // Check to see if the device supports zooming...
   if (zoomCaps.supported) {
      // Set HTML5 range control to min/max values of zoom
      var zoomControl = document.querySelector("input[type=range]");
      zoomControl.min = zoomCaps.min;
      zoomControl.max = zoomCaps.max;
      zoomControl.value = videoTrack.zoom;
      zoomControl.onchange = applySettingChanges;
   }
}

function applySettingChanges(e) {
   videoTrack.setConstraint("zoom", parseFloat(e.target.value));
}
</pre>
        </section>

        <section>
            <h2>Adding the local media tracks into a new media stream:</h2>

            <pre>
function mediaStarted() {
   return new MediaStream( [ videoTrack, audioTrack ]);
}
</pre>
        </section>

        <section>
            <h2>Take a photo, show the photo in an image tag:</h2>

            <pre>
function mediaStarted() {
   // Check if this device supports a photo mode...
   if (videoTrack.sourceType == "photo-camera") {
       videoTrack.onphoto = showPicture;
       // Turn on flash only for the snapshot...if available
       if (videoTrack.fillLightMode != "notavailable")
          videoTrack.setConstraint("fillLightMode", "flash");
       else
          console.info("Flash not available");
       videoTrack.takePhoto();
   }
}

function showPicture(e) {
   var img = document.querySelector("img");
   img.src = URL.createObjectURL(e.data);
}
</pre>
        </section>

        <section>
            <h2>Show a newly available device</h2>

            <p class="note">A newly available device occurs when the user plugs in a device that wasn't previously
                visible to the user agent.</p>

            <pre>
var lastSourceCount = VideoStreamTrack.getSourceIds().length;
setTimeout(function () {
   if (lastSourceCount != VideoStreamTrack.getSourceIds().length)
      alert("New device available! Do you want to use it?");
}, 1000 * 60); // Poll every minute
</pre>
        </section>

        <section>
            <h2>Show all available video devices (that the user authorizes):</h2>

            <pre>
var allSources = VideoStreamTrack.getSourceIds();
for (var i = 0; i &lt; allSources.length; i++) {
   var mediaStream = new MediaStream( new VideoStreamTrack({ mandatory: { sourceId: allSources[i] }}) );
   // Create a video element and add it to the UI
   var videoTag = document.createElement('video');
   videoTag.srcObject = mediaStream;
   document.body.appendChild(videoTag);
   // Request to have the track connected to a source device (queue these up in the for-loop)
   navigator.getUserMedia(mediaStream);
}
</pre>
        </section>
    </section>

    <section>
        <h1>Remove <code>LocalMediaStream</code> interface</h1>
        <p>This proposal recommends removing the derived <code>LocalMediaStream</code> interface. All relevant "local" information
            has been moved to the track level, and anything else that offers a convenience API for working with all the set of tracks
            on a MediaStream should just be added to the vanilla <code>MediaStream</code> interface itself.
        </p>

        <p>See the previous proposals for a statement on the rationale behind this recommendation.</p>
    </section>

	<section>
		<h1>Acknowledgements</h1>
		<p>I'd like to specially thank Anant Narayanan of Mozilla for collaborating on the new settings design, and EKR for his 2c. Also, thanks to
		Martin Thomson (Microsoft) for his comments and review, and other participants on the public-media-capture mailing list.
	</section>
  </body>
</html>


